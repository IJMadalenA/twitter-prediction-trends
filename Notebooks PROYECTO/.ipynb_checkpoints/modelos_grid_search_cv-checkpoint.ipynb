{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "\n",
    "#Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File C:/Users/Daniel/Documents/GitHub/SuperProyecto/Notebooks PROYECTO/csv definitivos/Q3_tweets_24_notendencias_variables.csv does not exist: 'C:/Users/Daniel/Documents/GitHub/SuperProyecto/Notebooks PROYECTO/csv definitivos/Q3_tweets_24_notendencias_variables.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d71aa97a128d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Cargamos y leemos el csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Daniel/Documents/GitHub/SuperProyecto/Notebooks PROYECTO/csv definitivos/Q3_tweets_24_notendencias_variables.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Daniel/Documents/GitHub/SuperProyecto/Notebooks PROYECTO/csv definitivos/Q3_tweets_25_notendencias_variables.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Daniel/Documents/GitHub/SuperProyecto/Notebooks PROYECTO/csv definitivos/Q1Q3_tweets_24_tendencias_variables.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File C:/Users/Daniel/Documents/GitHub/SuperProyecto/Notebooks PROYECTO/csv definitivos/Q3_tweets_24_notendencias_variables.csv does not exist: 'C:/Users/Daniel/Documents/GitHub/SuperProyecto/Notebooks PROYECTO/csv definitivos/Q3_tweets_24_notendencias_variables.csv'"
     ]
    }
   ],
   "source": [
    "#Cargamos y leemos el csv\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\Users\\Daniel\\Desktop\\csv definitivos/Q3_tweets_24_notendencias_variables.csv\", sep = \";\")\n",
    "df2 = pd.read_csv(\"C:\\Users\\Daniel\\Desktop\\csv definitivos/Q3_tweets_25_notendencias_variables.csv\", sep = \";\")\n",
    "df3 = pd.read_csv(\"C:\\Users\\Daniel\\Desktop\\csv definitivos/Q1Q3_tweets_24_tendencias_variables.csv\", sep = \";\")\n",
    "df4 = pd.read_csv(\"C:\\Users\\Daniel\\Desktop\\csv definitivoscsv definitivos/Q1Q3_tweets_25_tendencias_variables.csv\", sep = \";\")\n",
    "\n",
    "df1[\"target\"] = 0\n",
    "df2[\"target\"] = 0\n",
    "df3[\"target\"] = 1\n",
    "df4[\"target\"] = 1\n",
    "\n",
    "del(df1[\"Unnamed: 0\"])\n",
    "del(df2[\"Unnamed: 0\"])\n",
    "del(df3[\"Unnamed: 0\"])\n",
    "del(df4[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df1, df3])\n",
    "df_test = pd.concat([df2, df4])\n",
    "\n",
    "df_train.drop(\"start_lifetime\", axis = 1, inplace = True)\n",
    "df_test.drop(\"start_lifetime\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos train\n",
    "X = np.asarray(df_train.iloc[:,2:-2])\n",
    "y = np.asarray(df_train.target)\n",
    "\n",
    "#Obtenemos test\n",
    "X_test = df_test.iloc[:, 2:-2]\n",
    "y_test = df_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(columns = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Calculamos los mejores parametros para el modelo\n",
    "clf = RandomForestClassifier()\n",
    "clfparam_grid = {\"bootstrap\"         : [True, False],\n",
    "                 \"max_depth\"         : [10, 20, 30, 40, 50, 60, 70, None],\n",
    "                 \"max_features\"      : [\"auto\", \"sqrt\"],\n",
    "                 \"min_samples_leaf\"  : [1, 2, 4],\n",
    "                 \"min_samples_split\" : [2, 5, 10],\n",
    "                 \"n_estimators\"      : [200, 400, 600]}\n",
    "\n",
    "clf_search = GridSearchCV(clf, param_grid = clfparam_grid, cv = 3, verbose = 2, n_jobs = -1)\n",
    " \n",
    "model_result = clf_search.fit(X, y)\n",
    "best_model = model_result.best_estimator_\n",
    "final_model = best_model.fit(X,y)\n",
    "yhat = final_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy_score:\", accuracy_score(y_test, yhat))\n",
    "print(\"------------------------------------\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(classification_report(y_test, yhat))\n",
    "\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "row = {\"Model\"     : \"RandomForestClassifier\",\n",
    "       \"Accuracy\"  : round(accuracy_score(y_test, yhat), 3),\n",
    "       \"F1-Score\"  : round(f1_score(y_test,yhat), 3),\n",
    "       \"Precision\" : round(precision_score(y_test, yhat), 3),\n",
    "       \"Recall\"    : round(recall_score(y_test, yhat), 3),\n",
    "       \"AUC\"       : round(roc_auc, 3)}\n",
    "\n",
    "df_metrics = pd.concat([df_metrics, pd.DataFrame(row, index = [0])])\n",
    "\n",
    "\n",
    "# Confussion Matrix\n",
    "disp = plot_confusion_matrix(final_model, X_test, y_test,\n",
    "                             display_labels=[\"NT\", \"T\"],\n",
    "                             cmap = plt.cm.Blues,\n",
    "                             normalize = \"true\")\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area bajo la curva: \",auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, \"b\", label = \"AUC = %0.2f\" % roc_auc)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.ylabel(\"Sensibilidad\")\n",
    "plt.xlabel(\"1-Especificidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Calculamos los mejores parametros para el modelo\n",
    "clf = LogisticRegression()\n",
    "clfparam_grid = {\"C\"        : [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                 \"penalty\"  : [\"l1\", \"l2\"],\n",
    "                 \"max_iter\" : list(range(100,800,100)),\n",
    "                 \"solver\"   : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}\n",
    "\n",
    "clf_search = GridSearchCV(clf, param_grid = clfparam_grid, refit = True, verbose = 3, cv = 5)\n",
    "\n",
    "print(\"Mean Accuracy: %.3f\" % clf_search.best_score_)\n",
    "print(\"Config: %s\" % clf_search.best_params_)\n",
    "\n",
    "\n",
    "model_result = clf_search.fit(X, y)\n",
    "best_model = model_result.best_estimator_\n",
    "final_model = best_model.fit(X,y)\n",
    "yhat = final_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy_score:\", accuracy_score(y_test, yhat))\n",
    "print(\"------------------------------------\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(classification_report(y_test, yhat))\n",
    "\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "row = {\"Model\"     : \"LogisticRegression\",\n",
    "       \"Accuracy\"  : round(accuracy_score(y_test, yhat), 3),\n",
    "       \"F1-Score\"  : round(f1_score(y_test,yhat), 3),\n",
    "       \"Precision\" : round(precision_score(y_test, yhat), 3),\n",
    "       \"Recall\"    : round(recall_score(y_test, yhat), 3),\n",
    "       \"AUC\"       : round(roc_auc, 3)}\n",
    "\n",
    "df_metrics = pd.concat([df_metrics, pd.DataFrame(row, index = [0])])\n",
    "\n",
    "\n",
    "# Confussion Matrix\n",
    "disp = plot_confusion_matrix(final_model, X_test, y_test,\n",
    "                             display_labels=[\"NT\", \"T\"],\n",
    "                             cmap = plt.cm.Blues,\n",
    "                             normalize = \"true\")\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area bajo la curva: \",auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, \"b\", label = \"AUC = %0.2f\" % roc_auc)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.ylabel(\"Sensibilidad\")\n",
    "plt.xlabel(\"1-Especificidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos los mejores parametros para el modelo\n",
    "clf = GaussianNB()\n",
    "clfparam_grid = {\"var_smoothing\" : np.logspace(0, -9, num = 100)}\n",
    "clf_search = GridSearchCV(clf, param_grid = clfparam_grid, cv = 5, verbose = 1)\n",
    "\n",
    "\n",
    "model_result = clf_search.fit(X, y)\n",
    "best_model = model_result.best_estimator_\n",
    "final_model = best_model.fit(X,y)\n",
    "yhat = final_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy_score:\", accuracy_score(y_test, yhat))\n",
    "print(\"------------------------------------\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(classification_report(y_test, yhat))\n",
    "\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "row = {\"Model\"     : \"GaussianNB\",\n",
    "       \"Accuracy\"  : round(accuracy_score(y_test, yhat), 3),\n",
    "       \"F1-Score\"  : round(f1_score(y_test,yhat), 3),\n",
    "       \"Precision\" : round(precision_score(y_test, yhat), 3),\n",
    "       \"Recall\"    : round(recall_score(y_test, yhat), 3),\n",
    "       \"AUC\"       : round(roc_auc, 3)}\n",
    "\n",
    "df_metrics = pd.concat([df_metrics, pd.DataFrame(row, index = [0])])\n",
    "\n",
    "\n",
    "# Confussion Matrix\n",
    "disp = plot_confusion_matrix(final_model, X_test, y_test,\n",
    "                             display_labels=[\"NT\", \"T\"],\n",
    "                             cmap = plt.cm.Blues,\n",
    "                             normalize = \"true\")\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area bajo la curva: \",auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, \"b\", label = \"AUC = %0.2f\" % roc_auc)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.ylabel(\"Sensibilidad\")\n",
    "plt.xlabel(\"1-Especificidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos los mejores parametros para el modelo\n",
    "clf = KNeighborsClassifier()\n",
    "clfparam_grid = {\"n_neighbors\": [3,4,5,6,10],\n",
    "                 \"weights\"    : [\"uniform\", \"distance\"],\n",
    "                 \"metric\"     : [\"euclidean\", \"manhattan\"]}\n",
    "\n",
    "clf_search = GridSearchCV(clf, param_grid = clfparam_grid, verbose = 1, cv = 3, n_jobs = -1 )\n",
    "\n",
    "model_result = clf_search.fit(X, y)\n",
    "best_model = model_result.best_estimator_\n",
    "final_model = best_model.fit(X,y)\n",
    "yhat = final_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy_score:\", accuracy_score(y_test, yhat))\n",
    "print(\"------------------------------------\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(classification_report(y_test, yhat))\n",
    "\n",
    "probs = cfinal_modellf.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "row = {\"Model\"     : \"KNeighborsClassifier\",\n",
    "       \"Accuracy\"  : round(accuracy_score(y_test, yhat), 3),\n",
    "       \"F1-Score\"  : round(f1_score(y_test,yhat), 3),\n",
    "       \"Precision\" : round(precision_score(y_test, yhat), 3),\n",
    "       \"Recall\"    : round(recall_score(y_test, yhat), 3),\n",
    "       \"AUC\"       : round(roc_auc, 3)}\n",
    "\n",
    "df_metrics = pd.concat([df_metrics, pd.DataFrame(row, index = [0])])\n",
    "\n",
    "\n",
    "# Confussion Matrix\n",
    "disp = plot_confusion_matrix(final_model, X_test, y_test,\n",
    "                             display_labels=[\"NT\", \"T\"],\n",
    "                             cmap = plt.cm.Blues,\n",
    "                             normalize = \"true\")\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area bajo la curva: \",auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, \"b\", label = \"AUC = %0.2f\" % roc_auc)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.ylabel(\"Sensibilidad\")\n",
    "plt.xlabel(\"1-Especificidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos los mejores parametros para el modelo\n",
    "clf = DecisionTreeClassifier()\n",
    "clfparam_grid = {\"criterion\" : [\"gini\", \"entropy\"],\n",
    "                 \"max_depth\" : [2,4,6,8,10,12]}\n",
    "\n",
    "clf_search = GridSearchCV(clf, param_grid = clfparam_grid, refit = True, verbose = 3, cv=5)\n",
    "\n",
    " \n",
    "model_result = clf_search.fit(X, y)\n",
    "best_model = model_result.best_estimator_\n",
    "final_model = best_model.fit(X,y)\n",
    "yhat = final_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy_score:\", accuracy_score(y_test, yhat))\n",
    "print(\"------------------------------------\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(classification_report(y_test, yhat))\n",
    "\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "row = {\"Model\"     : \"DecisionTreeClassifier\",\n",
    "       \"Accuracy\"  : round(accuracy_score(y_test, yhat), 3),\n",
    "       \"F1-Score\"  : round(f1_score(y_test,yhat), 3),\n",
    "       \"Precision\" : round(precision_score(y_test, yhat), 3),\n",
    "       \"Recall\"    : round(recall_score(y_test, yhat), 3),\n",
    "       \"AUC\"       : round(roc_auc, 3)}\n",
    "\n",
    "df_metrics = pd.concat([df_metrics, pd.DataFrame(row, index = [0])])\n",
    "\n",
    "# Confussion Matrix\n",
    "disp = plot_confusion_matrix(final_model, X_test, y_test,\n",
    "                             display_labels=[\"NT\", \"T\"],\n",
    "                             cmap = plt.cm.Blues,\n",
    "                             normalize = \"true\")\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area bajo la curva: \",auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, \"b\", label = \"AUC = %0.2f\" % roc_auc)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.ylabel(\"Sensibilidad\")\n",
    "plt.xlabel(\"1-Especificidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos los mejores parametros para el modelo\n",
    "clf = svm.SVC()\n",
    "clfparam_grid = {\"C\"           : [5, 10, 15],\n",
    "                 \"gamma\"       : [\"auto\", 0.001, 0.00001, 0.000001],\n",
    "                 \"kernel\"      : [\"rbf\", \"poly\", \"linear\"],\n",
    "                 \"shrinking\"   : [True, False],\n",
    "                 \"probability\" : [True, False]}\n",
    "\n",
    "clf_search = GridSearchCV(clf, param_grid = clfparam_grid, refit = True, verbose = 3, cv = 5, n_jobs = -1)\n",
    "\n",
    "model_result = clf_search.fit(X, y)\n",
    "best_model = model_result.best_estimator_\n",
    "final_model = best_model.fit(X,y)\n",
    "yhat = final_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy_score:\", accuracy_score(y_test, yhat))\n",
    "print(\"------------------------------------\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, yhat))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(classification_report(y_test, yhat))\n",
    "\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "row = {\"Model\"     : \"SVM (Classifier)\",\n",
    "       \"Accuracy\"  : round(accuracy_score(y_test, yhat), 3),\n",
    "       \"F1-Score\"  : round(f1_score(y_test,yhat), 3),\n",
    "       \"Precision\" : round(precision_score(y_test, yhat), 3),\n",
    "       \"Recall\"    : round(recall_score(y_test, yhat), 3),\n",
    "       \"AUC\"       : round(roc_auc, 3)}\n",
    "\n",
    "df_metrics = pd.concat([df_metrics, pd.DataFrame(row, index = [0])])\n",
    "\n",
    "# Confussion Matrix\n",
    "disp = plot_confusion_matrix(final_model, X_test, y_test,\n",
    "                             display_labels=[\"NT\", \"T\"],\n",
    "                             cmap = plt.cm.Blues,\n",
    "                             normalize = \"true\")\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "probs = final_model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area bajo la curva: \",auc(fpr, tpr))\n",
    "plt.plot(fpr, tpr, \"b\", label = \"AUC = %0.2f\" % roc_auc)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.ylabel(\"Sensibilidad\")\n",
    "plt.xlabel(\"1-Especificidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_metrics.to_csv(\"metricas_modelos.csv\", sep = \";\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
