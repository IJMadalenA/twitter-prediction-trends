{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(string):\n",
    "    if string != \"[]\":\n",
    "        string = json.loads(string.replace(\"'\", \"\\\"\"))\n",
    "        return \",\".join([s[\"screen_name\"] for s in string])\n",
    "    return \"\"\n",
    "\n",
    "def to_list(list_):\n",
    "    if list_ != \"[]\":\n",
    "        list_ = list_[1:-1]\n",
    "        list_ = list_.split(\",\")\n",
    "        return \",\".join([s.strip().strip(\"'\") for s in list_])\n",
    "    return \"\"\n",
    "\n",
    "def normalize(s):\n",
    "    replacements = ((\"á\", \"a\"), (\"é\", \"e\"), (\"í\", \"i\"), (\"ó\", \"o\"), (\"ú\", \"u\"))\n",
    "    for a, b in replacements:\n",
    "        s = s.lower()\n",
    "        s = s.replace(a, b)\n",
    "    return s\n",
    "\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r\"\", text)\n",
    "\n",
    "def cleanTxt(text):\n",
    "    text = re.sub(r\"@[a-zA-Z0-9]+\", \"\", text) #Removes @mentions\n",
    "    text = re.sub(r\"#\", \"\", text) #Removing the \"#\" symbol\n",
    "    text = re.sub(r\"RT[\\s]+\", \"\", text) #Removing RT\n",
    "    text = re.sub(r\"https?:\\/\\/\\S+\", \"\", text) #Remove the hyperlink\n",
    "    return text\n",
    "\n",
    "def replace_punct(s):\n",
    "    for i in string.punctuation:\n",
    "        if i in s:\n",
    "            s = s.replace(i, \"\").strip()\n",
    "    return s\n",
    "\n",
    "def replace_num(s):\n",
    "    for i in [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]:\n",
    "        s = s.replace(i, \"\")\n",
    "    return s\n",
    "\n",
    "def tokenizador(text):\n",
    "    important_words = []\n",
    "    for word in text.split(\" \"):\n",
    "        if word not in stopwords.words(\"spanish\"):\n",
    "            if word != \"\":\n",
    "                important_words.append(word)\n",
    "    return \" \".join(important_words).strip()\n",
    "\n",
    "def foo(text):\n",
    "    forbidden = (\"?\", \"¿\", \"¡\", \"!\", \",\", \".\", \";\", \":\", \"-\", \"'\", \"+\", \"$\", \"/\", \"*\",'«','»', \"~\", \"(\", \")\")\n",
    "    aux = \"\"\n",
    "    for v in text:\n",
    "        if not v in forbidden:\n",
    "            aux += v\n",
    "    return aux\n",
    "\n",
    "def quita_palabras_pequeñas(text):\n",
    "    return \" \".join([word for word in text.split(\" \") if len(word) > 2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_c = pd.read_csv(\"C:/Users/Daniel/Desktop/csv/dia 24/trends/23_24f.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = pd.read_csv(\"C:/Users/Daniel/Desktop/csv/dia 24/trends/24_25f.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (0,1,2,22,26) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_e = pd.read_csv(\"C:/Users/Daniel/Desktop/csv/dia 24/trends/24f_pilar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_f = pd.read_csv(\"C:/Users/Daniel/Desktop/csv/dia 24/trends/dia_24_tendencias_daniel.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = pd.read_csv(\"C:/Users/Daniel/Desktop/csv/dia 24/trends/24f_ismael.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_c, df_d, df_e, df_f, df_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tweets_24_tendencias_raw_daniel.csv\", sep = \";\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"conversation_id\", \"cashtags\", \"timezone\", \"user_id\", \"name\", \"near\", \"geo\", \"source\",\n",
    "                   \"user_rt_id\", \"user_rt\", \"retweet_id\", \"retweet_date\", \"translate\", \"trans_src\",\n",
    "                   \"trans_dest\", \"place\", \"quote_url\", \"thumbnail\", \"created_at\", \"id\", \"link\"]\n",
    "\n",
    "df.drop(columns_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "df = df[df.language == \"es\"]\n",
    "\n",
    "df.drop(\"language\", axis = 1, inplace = True)\n",
    "\n",
    "df = df.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"day\"] = df.date.apply(lambda x : x[-2:])\n",
    "df.drop(\"Unnamed: 0\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.day == \"24\"]\n",
    "df = df.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to_rows = []\n",
    "for num, row in enumerate(df.reply_to):\n",
    "    try:\n",
    "        to_dict(row)\n",
    "    except:\n",
    "        reply_to_rows.append(num)\n",
    "\n",
    "print(\"indices a dropear:\", len(reply_to_rows))\n",
    "        \n",
    "df.drop(reply_to_rows, inplace = True)\n",
    "\n",
    "df.reply_to = df.reply_to.apply(to_dict)\n",
    "\n",
    "df = df.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_rows = []\n",
    "for num, row in enumerate(df.mentions):\n",
    "    try:\n",
    "        to_dict(row)\n",
    "    except:\n",
    "        mention_rows.append(num)\n",
    "        \n",
    "print(\"indices a dropear:\", len(mention_rows))\n",
    "        \n",
    "df.drop(mention_rows, inplace = True)\n",
    "\n",
    "df.mentions = df.mentions.apply(to_dict)\n",
    "\n",
    "df = df.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_rows = []\n",
    "for num, row in enumerate(df.hashtags):\n",
    "    try:\n",
    "        to_list(row)\n",
    "    except:\n",
    "        hashtags_rows.append(num)\n",
    "        \n",
    "print(\"indices a dropear:\", len(hashtags_rows))\n",
    "        \n",
    "df.drop(hashtags_rows, inplace = True)\n",
    "\n",
    "df.hashtags = df.hashtags.apply(to_list)\n",
    "\n",
    "df = df.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.photos = df.photos.apply(lambda x : 1 if x != \"[]\" else 0)\n",
    "df.retweet = df.retweet.apply(lambda x : 1 if x == \"True\" else 0)\n",
    "df.urls = df.urls.apply(lambda x : 1 if x != \"[]\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"month\"] = df.date.apply(lambda x : x[5 : 7])\n",
    "df[\"day\"] = df.date.apply(lambda x : x[-2:])\n",
    "\n",
    "df[\"hour\"] = df.time.apply(lambda x : x[:2])\n",
    "df[\"minute\"] = df.time.apply(lambda x : x[3:5])\n",
    "df[\"second\"] = df.time.apply(lambda x : x[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mentions_count\"] = [len(mention.split(\",\")) if type(mention) == str else 0 for mention in df.mentions]\n",
    "\n",
    "df[\"reply_to_count\"] = [len(reply.split(\",\")) if type(reply) == str else 0 for reply in df.reply_to]\n",
    "\n",
    "df[\"hashtags_count\"] =  [len(hashtag.split(\",\")) if type(hashtag) == str else 0 for hashtag in df.hashtags]\n",
    "\n",
    "df[\"interaccion\"] = [rt + re + lk for rt, re, lk in zip(df.retweets_count, df.replies_count, df.likes_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.tweet = df.tweet.apply(normalize)\n",
    "df.tweet = df.tweet.apply(deEmojify)\n",
    "df.tweet = df.tweet.apply(cleanTxt)\n",
    "df.tweet = df.tweet.apply(replace_punct)\n",
    "df.tweet = df.tweet.apply(replace_num)\n",
    "\n",
    "df.tweet = df.tweet.apply(tokenizador)\n",
    "df.tweet = df.tweet.apply(foo)\n",
    "df.tweet = df.tweet.apply(quita_palabras_pequeñas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trend in df.trend.unique():\n",
    "    print(trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tweets_24_tendencias_preprocesado.csv\", sep =\";\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.concat([df_c, df_d, df_e, df_f, df_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.drop_duplicates(inplace = True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_csv(\"tweets_24_tendencias_raw.csv\", sep = \";\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.DataFrame(df.trend.value_counts()).reset_index()\n",
    "df_summary.columns = [\"trend\", \"total_tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_summary[\"total_hashtags\"]    = [df[df.trend == trend].hashtags_count.sum() for trend in df_summary.trend]\n",
    "\n",
    "df_summary[\"total_mentions\"]    = [df[df.trend == trend].mentions_count.sum() for trend in df_summary.trend]\n",
    "\n",
    "df_summary[\"total_reply_to\"]    = [df[df.trend == trend].reply_to_count.sum() for trend in df_summary.trend]\n",
    "\n",
    "df_summary[\"total_url\"]         = [df[df.trend == trend].urls.sum()           for trend in df_summary.trend]\n",
    "\n",
    "df_summary[\"total_photo\"]       = [df[df.trend == trend].photos.sum()         for trend in df_summary.trend]\n",
    "\n",
    "df_summary[\"total_retweets\"]    = [df[df.trend == trend].retweets_count.sum() for trend in df_summary.trend]\n",
    "\n",
    "df_summary[\"total_likes\"]       = [df[df.trend == trend].likes_count.sum()    for trend in df_summary.trend]\n",
    "\n",
    "df_summary[\"total_replies\"]     = [df[df.trend == trend].replies_count.sum()  for trend in df_summary.trend]\n",
    "\n",
    "df_summary[\"total_interaction\"] = [df[df.trend == trend].interaccion.sum()    for trend in df_summary.trend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifetime = []\n",
    "for trend in df_summary.trend:\n",
    "    start_end = list(df[df.trend == trend].sort_values(\"time\").time.iloc[[0, -1]])\n",
    "    start_end = int(start_end[1][0:2]) - int(start_end[0][0:2])\n",
    "    lifetime.append(start_end)\n",
    "    \n",
    "df_summary[\"lifetime\"] = lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_intervals = [\"0{}:00:00\".format(i) if i < 10 else \"{}:00:00\".format(i) for i in range(24)] + [\"23:59:59\"]\n",
    "\n",
    "tweet_count_labels = [\"tweet_count_{}{}\".format(i, i + 1) for i in range(24)]\n",
    "\n",
    "for num, label in enumerate(tweet_count_labels):\n",
    "    df_summary[label] = [df[(df.time.between(time_intervals[num], time_intervals[num + 1])) & (df.trend == trend)].shape[0] for trend in df_summary.trend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_vel_labels = [\"tweet_vel_{}{}\".format(i, i + 1) for i in range(24)]\n",
    "\n",
    "velocidades = []\n",
    "for i in range(df_summary.shape[0]):\n",
    "    counts = [0] + list(df_summary.loc[i, tweet_count_labels])\n",
    "    vel = [counts[i] - counts[i - 1] for i in range(1, len(counts))]\n",
    "    velocidades.append(vel)\n",
    "    \n",
    "velocidades = np.array(velocidades)\n",
    "\n",
    "df_summary = pd.concat([df_summary, pd.DataFrame(velocidades, columns = tweet_vel_labels)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_acl_labels = [\"tweet_acl_{}{}\".format(i, i + 1) for i in range(24)]\n",
    "\n",
    "aceleraciones = []\n",
    "for i in range(df_summary.shape[0]):\n",
    "    counts = [0] + list(df_summary.loc[i, tweet_vel_labels])\n",
    "    acl = [counts[i] - counts[i - 1] for i in range(1, len(counts))]\n",
    "    aceleraciones.append(acl)\n",
    "    \n",
    "aceleraciones = np.array(aceleraciones)\n",
    "\n",
    "df_summary = pd.concat([df_summary, pd.DataFrame(aceleraciones, columns = tweet_acl_labels)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count_labels = [\"user_count_{}{}\".format(i, i + 1) for i in range(24)]\n",
    "\n",
    "for num, label in enumerate(user_count_labels):\n",
    "    df_summary[label] = [df[(df.time.between(time_intervals[num], time_intervals[num + 1])) & (df.trend == trend)].username.unique().shape[0] for trend in df_summary.trend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv(\"tweets_24_tendencia_variables.csv\", sep = \";\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
